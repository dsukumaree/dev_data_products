corSN <- by(thresholdData,thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData,thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
round(corSN, 4)
} else corSN <- 0
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,4)
} else {
corSN <- 0
}
}
corr <- function(directory, threshold = 0) {
completeData <- complete(directory)
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
}
}
corr <- function(directory, threshold = 0) {
completeData <- complete(directory)
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
length(corSN) <- 0
corSN
}
}
}
corr <- function(directory, threshold = 0) {
pollutionData <- data.frame()
completeData <- complete(directory)
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
length(corSN) <- 0
corSN
}
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
}
}
corr <- function(directory, threshold = 0) {
pollutionData <- data.frame()
completeData <- complete(directory)
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
length(corSN) <- 0
corSN
}
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
}
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
corSN <- round(corSN,5)
} else {
corSN <- 0
length(corSN) <- 0
corSN
}
}
corr <- function(directory, threshold = 0 , id = 1:332) {
pollutionData <- data.frame()
completeData <- data.frame()
for(i in id) {
if (i < 10 ) {
path <- paste("./",directory, "/00", i,".csv",sep="")
}
else if ( i >= 10 && i < 100)  {
path <- paste("./",directory, "/0", i,".csv",sep="")
}
else
path <- paste("./",directory, "/", i,".csv",sep="")
pollutionData_tmp <- read.csv(path)
pollutionData_tmp <- pollutionData_tmp[complete.cases(pollutionData_tmp[,2],pollutionData_tmp[,3]),]
pollutionData <- rbind(pollutionData, pollutionData_tmp)
if (nrow(pollutionData_tmp) != 0) {
completeData_tmp <- aggregate(pollutionData_tmp$ID, by = list(pollutionData_tmp$ID), FUN=length)
completeData <- rbind(completeData, completeData_tmp)
} else {
tmp <- data.frame(Group.1 = i, x=0)
completeData <- rbind(completeData, tmp)
}
}
colnames(completeData) <- c("id", "nobs")
thresholdID <- completeData[(completeData$nobs > threshold),]
thresholdRows <- (pollutionData$ID %in% thresholdID$id)
thresholdData <- pollutionData[thresholdRows,]
if (nrow(thresholdData) > 0) {
corSN <- by(thresholdData, thresholdData$ID, FUN=function(X) cor(X$sulfate, X$nitrate))
} else {
corSN <- 0
length(corSN) <- 0
corSN
}
}
This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).
When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
run_Analysis.R
========================================================
This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).
When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
```{r}
summary(cars)
```
You can also embed plots, for example:
```{r fig.width=7, fig.height=6}
plot(cars)
```
run_Analysis.R
========================================================
This is an R Markdown document. Markdown is a simple formatting syntax for authoring web pages (click the **Help** toolbar button for more details on using R Markdown).
When you click the **Knit HTML** button a web page will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:
READ ME - run_Analysis.R
========================================================
This script merges two data sets obtained from the experiment detailed below to:
* Create a tidy data set with appropriate labels and descriptive data elements. Extract only means and std deviation measures from this dataset.
* Summarize the average of measures in the first dataset as a separate dataset.
Experiment
--------------------------------------------------------
The experiments have been carried out with a group of 30 volunteers within an age bracket of 19-48 years. Each person performed six activities (WALKING, WALKING_UPSTAIRS, WALKING_DOWNSTAIRS, SITTING, STANDING, LAYING) wearing a smartphone (Samsung Galaxy S II)
on the waist. Using its embedded accelerometer and gyroscope,  3-axial linear acceleration and 3-axial angular velocity at a constant rate of 50Hz were captured.The obtained dataset was randomly partitioned into two sets, where 70% of the volunteers was selected for generating the training data and 30% the test data.
Dataset Information:
--------------------------------------------------------
### For each record the experiment provides:
* Triaxial acceleration from the accelerometer (total acceleration) and the estimated body acceleration.
* Triaxial Angular velocity from the gyroscope.
* A 561-feature vector with time and frequency domain variables.
* Its activity label.
* An identifier of the subject who carried out the experiment.
### The dataset includes the following files:
* README.txt
* features_info.txt: Shows information about the variables used on the feature vector.
* features.txt: List of all features.
* activity_labels.txt: Links the class labels with their activity name.
* train/X_train.txt: Training set.
* train/y_train.txt: Training labels.
* test/X_test.txt: Test set.
* test/y_test.txt: Test labels.
#### The following files are available for the train and test data. Their descriptions are equivalent.
* train/subject_train.txt: Each row identifies the subject who performed the activity for each window sample. Its range is from 1 to 30.
* train/Inertial Signals/total_acc_x_train.txt: The acceleration signal from the smartphone accelerometer X axis in standard gravity units 'g'. Every row shows a 128 element vector. The same description applies for the 'total_acc_x_train.txt' and
total_acc_z_train.txt files for the Y and Z axis.
* train/Inertial Signals/body_acc_x_train.txt: The body acceleration signal obtained by subtracting the gravity from the total acceleration.
* train/Inertial Signals/body_gyro_x_train.txt: The angular velocity vector measured by the gyroscope for each window sample.
The units are radians/second.
note: For the purpose of this analysis the raw data provided in 'Inertial Signals' folder was not considered.
#### Activity Codes & Names
* 1 WALKING
* 2 WALKING_UPSTAIRS
* 3 WALKING_DOWNSTAIRS
* 4 SITTING
* 5 STANDING
* 6 LAYING
run_Analysis.R:
--------------------------------------------------------
### Libraries used:
* plyr
* reshape2
### High Level Logic:
* Unzip provided dataset into your working directory. Script assumes that data files are present in 'UCI HAR Dataset' directory in        your working directory.
* Load 'subject_test.txt' and 'X_test.txt' into 'Subject_test' and 'X_test' dataframes.
* Add 'Subject Id' from 'Subject_test' into 'X_test' to combine measures with subjects
* Assign feature names from 'features.txt' as column names for the measures in X_test
* Join the data in 'Y_test.txt' (containing activity id) with the data in 'activity_labels.txt' to get activity names.
* Add 'Activity Name' obtained from above step to the X_test data frame
* Identify columns that have 'std()' or 'mean()' in the column names. This includes 'meanFreq' columns as well.
* Create a dataset for 'Test' subjects, with subject id, activity name and the columns identified in the above step. This is 'XTestData'
* The steps above are repeated for the 'Train' dataset to create 'XTrainData'
* Append the 'Train' dataset to the 'Test' dataset to create a combined dataset with 'Subject Id', 'Activity Name', and std and mean  measures. This is the 'TestTrainCombined'
* Create a second dataset 'avgBySubjActy'. This dataset contains the average of the std and mean measures obtained above and is grouped by 'Subject Id' and 'Activity Name'.
* Create output file 'CombinedTidyData.txt' from the combined data set, 'TestTrainCombined'
* Create output file 'AvgBySubjectActivity.txt' from the second data set, 'avgBySubjActy'
### Assumptions:
* For this analysis, precalculated std and mean values from 'X_test.txt' and 'X_train.txt' were considered. Raw data from 'Inertial Signals' folder was not used
* To identify mean and std measures 'grep(std())' and 'grep(mean())' functions were used. The results include 'meanFreq()' variables.
READ ME - run_Analysis.R
========================================================
This script merges two data sets obtained from the experiment detailed below to:
* Create a tidy data set with appropriate labels and descriptive data elements. Extract only means and std deviation measures from this dataset.
* Summarize the average of measures in the first dataset as a separate dataset.
READ ME run_Analysis.R
========================================================
========================================================
README run_Analysis.R
========================================================
```
library(shiny)
shinyServer(
function(input, output) {
}
)
library(shiny)
shinyUI(pageWithSidebar(
headerPanel("Data science FTW!"),
sidebarPanel(
h3('Sidebar text')
),
mainPanel(
h3('Main Panel text')
)
))
library(manipulate)
myPlot <- function(s) {
plot(cars$dist - mean(cars$dist), cars$speed - mean(cars$speed))
abline(0, s)
}
manipulate(myPlot(s), slider = x(0, 2, step = 0.1))
manipulate(myPlot(s), s = slider(0, 2, step = 0.1))
manipulate(myPlot(s), x.s = slider(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
manipulate(myPlot, s = slider(0, 2, step = 0.1))
install.packages("devtools")
library(devtools)
install_github('slidify','ramnathv')
myPlot <- function(beta){
y <- galton$child - mean(galton$child)
x <- galton$parent - mean(galton$parent)
freqData <- as.data.frame(table(x, y))
names(freqData) <- c("child", "parent", "freq")
plot(
as.numeric(as.vector(freqData$parent)),
as.numeric(as.vector(freqData$child)),
pch = 21, col = "black", bg = "lightblue",
cex = .15 * freqData$freq,
xlab = "parent",
ylab = "child"
)
abline(0, beta, lwd = 3)
points(0, 0, cex = 2, pch = 19)
mse <- mean( (y - beta * x)^2 )
title(paste("beta = ", beta, "mse = ", round(mse, 3)))
}
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
library(manipulate)
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
galton <- UsingR::galton
manipulate(myPlot(beta), beta = slider(0.4, .8, step = 0.02))
cor(galton$child, galton$parent)
getwd()
setwd("./Desktop/Data%Science-Coursera")
setwd("./Desktop/Coursera/Data Science-Coursera")
setwd("/Users/spicychakra/Desktop/Data Science - Coursera/Data Products")
getwd()
library(slidify)
author("height_predictor")
## Mother's Height in cm
mHeight <- 150
## Father's Height in cm
fHeight <- 170
## child's sex - "1" for female and "2" for male
cSex <- 1
if (cSex == 1){
cHeight <- ((fHeight - 13) + mHeight)/2 }
else {
cHeight <- ((mHeight + 13) + fHeight)/2 }
## Mother's Height in cm
mHeight <- 150
## Father's Height in cm
fHeight <- 170
## child's sex - "1" for female and "2" for male
cSex <- 1
if (cSex == 1) cHeight <- ((fHeight - 13) + mHeight)/2 }
else cHeight <- ((mHeight + 13) + fHeight)/2
if (cSex == 1) cHeight <- ((fHeight - 13) + mHeight)/2
## Mother's Height in cm
mHeight <- 150
## Father's Height in cm
fHeight <- 170
## child's sex - "1" for female and "2" for male
cSex <- 1
if (cSex == 1) cHeight <- ((fHeight - 13) + mHeight)/2
else cHeight <- ((mHeight + 13) + fHeight)/2
## Mother's Height in cm
mHeight <- 150
## Father's Height in cm
fHeight <- 170
## child's sex - "1" for female and "2" for male
cSex <- 1
if (cSex == 1)
cHeight <- ((fHeight - 13) + mHeight)/2
else
cHeight <- ((mHeight + 13) + fHeight)/2
## Mother's Height in cm
mHeight <- 150
## Father's Height in cm
fHeight <- 170
## child's sex - "1" for female and "2" for male
cSex <- 1
if (cSex == 1) cHeight <- ((fHeight - 13) + mHeight)/2  else  cHeight <- ((mHeight + 13) + fHeight)/2
devtools::install_github('rstudio/shinyapps')
library(shinyapps)
library(shiny)
getwd()
setwd("../.")
getwd()
shinyapps::setAccountInfo(name='dsuk', token='92AA7ADFC1477B531376EE767D1D0EA4', secret='C6cO5Ux1SGyQ/fIzJNLtgG9Dv9Um+Sg3QioWILZz')
deployApp()
deployApp(appName="HeightPredictor")
install_github('rCharts', 'ramnathv')
install.packages("rjson")
install.packages("rMaps")
install.packages("fields")
install.packages("yhatr")
deployApp(appName="HeightPredictor")
install.packages("rMaps")
install_github('ramnathv/rMaps')
deployApp(appName="HeightPredictor")
deployApp(appName="HeightPredict",account="dsuk")
library(shinyapps)
library(shiny)
getwd()
ls
setwd("./shiny")
getwd()
runApp()
deployApp(appName="HeightPredict",account="dsuk")
getwd()
setwd("../height_predictor")
getwd()
slidify("index.Rmd")
library(slidify)
slidify("index.Rmd")
publish(user="dsukumaree", repo="data_products")
publish(user="dsukumaree", repo="https://github.com/dsukumaree/data_products")
publish(user="dsukumaree", repo="data_products")
git init
git commit --allow-empty -m 'Initial Commit'
git checkout -b gh-pages
touch index.Rmd
git init
exit()
quit()
getwd()
publish(user="dsukumaree", repo="dev_data_products")
library(slidify)
publish(user="dsukumaree", repo="dev_data_products")
quit()
library(slidify)
slidify("index.Rmd")
publish(user="dsukumaree", repo="dev_data_products")
quit()
